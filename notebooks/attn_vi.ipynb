{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenlidong/.conda/envs/py_38_torch_113_pyg/lib/python3.8/site-packages/torch_geometric/typing.py:90: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.27' not found (required by /home/chenlidong/.conda/envs/py_38_torch_113_pyg/lib/python3.8/site-packages/torch_spline_conv/_basis_cuda.so)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/chenlidong/polymer-chemprop-master/chemprop/\")\n",
    "from args import TrainArgs\n",
    "from features import mol2graph, BatchMolGraph, get_atom_fdim, get_bond_fdim\n",
    "from nn_utils import get_activation_function, index_select_ND\n",
    "from models import MoleculeModel\n",
    "from data import MoleculeDatapoint,MoleculeDataset\n",
    "import pdb\n",
    "import torch\n",
    "from chemprop.utils import load_checkpoint\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.bias\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.bias\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Warning: Pretrained parameter \"ffn.layers.0.linear.weight\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.0.linear.bias\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.0.bn.weight\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.0.bn.bias\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.0.bn.running_mean\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.0.bn.running_var\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.0.bn.num_batches_tracked\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.1.linear.weight\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.1.linear.bias\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.1.bn.weight\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.1.bn.bias\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.1.bn.running_mean\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.1.bn.running_var\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.1.bn.num_batches_tracked\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.2.linear.weight\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.2.linear.bias\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.2.bn.weight\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.2.bn.bias\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.2.bn.running_mean\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.2.bn.running_var\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.2.bn.num_batches_tracked\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.3.linear.weight\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.3.linear.bias\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.3.bn.weight\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.3.bn.bias\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.3.bn.running_mean\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.3.bn.running_var\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.3.bn.num_batches_tracked\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.4.linear.weight\" cannot be found in model parameters.\n",
      "Warning: Pretrained parameter \"ffn.layers.4.linear.bias\" cannot be found in model parameters.\n",
      "Moving model to cuda\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint(\"/home/chenlidong/polymer-chemprop-master/data/polymer-chemprop-data-main/results/vipea/cv9-monomer/master/checkpoints/chemprop_checkpoints_wDMPNN/0/12138/fold_0/model_0/model.pt\",device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = MoleculeDatapoint(smiles=[\"N c 1 n c ( C 2 C C ( N ) C 2 ) c c ( N 2 C C N ( C C ( = O ) N 3 C C C C 3 ) C C 2 ) n 1 . C C ( = O ) O C ( = O ) C S C C S C C ( = O ) O C ( C ) = O\".replace(\" \",\"\")],\n",
    "                 targets= [1.,2.],\n",
    "                 ctype=0,\n",
    "                 mtype=0,\n",
    "                 data_weight= 1,\n",
    "                #  features: np.ndarray = None,\n",
    "                #  features_generator: List[str] = None,\n",
    "                #  phase_features: List[float] = None,\n",
    "                #  atom_features: np.ndarray = None,\n",
    "                #  atom_descriptors: np.ndarray = None,\n",
    "                #  bond_features: np.ndarray = None,\n",
    "                #  overwrite_default_atom_features: bool = False,\n",
    "                #  overwrite_default_bond_features: bool = False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = MoleculeDataset([point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_batch, features_batch, target_batch, atom_descriptors_batch, atom_features_batch, bond_features_batch, data_weights_batch = \\\n",
    "            batch.batch_graph(), batch.features(), batch.targets(), batch.atom_descriptors(), \\\n",
    "            batch.atom_features(), batch.bond_features(), batch.data_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.6237, 0.1547]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(mol_batch, features_batch, atom_descriptors_batch, atom_features_batch, bond_features_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualize_atom_attention(viz_dir: str,\n",
    "                             smiles: str,\n",
    "                             num_atoms: int,\n",
    "                             attention_weights: torch.FloatTensor,\n",
    "                             prefix):\n",
    "    \"\"\"\n",
    "    Saves figures of attention maps between atoms. Note: works on a single molecule, not in batch\n",
    "    :param viz_dir: Directory in which to save attention map figures.\n",
    "    :param smiles: Smiles string for molecule.\n",
    "    :param num_atoms: The number of atoms in this molecule.\n",
    "    :param attention_weights: A num_atoms x num_atoms PyTorch FloatTensor containing attention weights.\n",
    "    \"\"\"\n",
    "    if type(smiles) == str:\n",
    "        mol_name = smiles\n",
    "        print('Saving {0} ({1} atoms)'.format(smiles, num_atoms))\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "    else:\n",
    "        mol = smiles\n",
    "        mol_name = Chem.MolToSmiles(mol)\n",
    "        print('Saving Similarity map of molecule: {0} ({1} atoms)'.format(\n",
    "            mol_name, num_atoms))\n",
    "\n",
    "    smiles_viz_dir = viz_dir\n",
    "    os.makedirs(smiles_viz_dir, exist_ok=True)\n",
    "    atomSum_weights = np.zeros(num_atoms)\n",
    "\n",
    "    # attention_weights = (attention_weights[4] + attention_weights[5]) / 2\n",
    "\n",
    "    for a in range(num_atoms):\n",
    "        a_weights = attention_weights[a].cpu().data.numpy()\n",
    "        atomSum_weights += a_weights\n",
    "\n",
    "    Amean_weight = atomSum_weights / num_atoms\n",
    "    # print(Amean_weight)\n",
    "    # 计算平均值和标准差\n",
    "    mean_value = np.mean(Amean_weight)\n",
    "    std_deviation = np.std(Amean_weight)\n",
    "\n",
    "    # 根据平均值和标准差来确定阈值\n",
    "    threshold0 = mean_value + 2 * std_deviation  # 例如，可以选择平均值加两倍标准差作为阈值\n",
    "    threshold1 = mean_value - 2 * std_deviation \n",
    "    print(threshold0)\n",
    "    print(threshold1)\n",
    "    truncated_list = [i if i >= threshold1 else threshold1 for i in[num if num <= threshold0 else threshold0 for num in Amean_weight]]\n",
    "    # print(truncated_list)\n",
    "    Amean_weight = truncated_list\n",
    "    nanMean = np.nanmean(Amean_weight)\n",
    "\n",
    "    save_path = os.path.join(\n",
    "        smiles_viz_dir, f'{mol_name.replace(\"/\", \"\")}{prefix}.png')\n",
    "\n",
    "    fig = SimilarityMaps.GetSimilarityMapFromWeights(mol, Amean_weight-nanMean,\n",
    "                                                     alpha=0.3,\n",
    "                                                     size=(300, 300))\n",
    "\n",
    "    fig.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.Chem.Draw import SimilarityMaps\n",
    "# from rdkit import Chem\n",
    "# fig = SimilarityMaps.GetSimilarityMapFromWeights(Chem.MolFromSmiles(\"*C#*\"), [1,2,1],\n",
    "#                                                     alpha=0.3,\n",
    "#                                                     size=(300, 300))\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "attns = torch.load(\"/home/chenlidong/polyAttn/notebooks/attns_homo_0_3.pt\",map_location=torch.device('cpu'))\n",
    "smiles = \"[*]Oc1ccc(S(=O)(=O)c2ccc(-c3ccc(-c4ccc(S(=O)(=O)c5ccc([*])cc5)cc4)cc3)cc2)cc1\".replace(\" \",\"\")\n",
    "atom_num = Chem.MolFromSmiles(smiles).GetNumAtoms()\n",
    "idx = 6\n",
    "atom_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47, 47])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(attns[6],dim=0)[:39,:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving [*]Oc1ccc(S(=O)(=O)c2ccc(-c3ccc(-c4ccc(S(=O)(=O)c5ccc([*])cc5)cc4)cc3)cc2)cc1 (39 atoms)\n",
      "0.1236404109782598\n",
      "-0.07235836336063144\n",
      "Saving [*]Oc1ccc(S(=O)(=O)c2ccc(-c3ccc(-c4ccc(S(=O)(=O)c5ccc([*])cc5)cc4)cc3)cc2)cc1 (39 atoms)\n",
      "0.12634801723545352\n",
      "-0.07506596577598167\n",
      "Saving [*]Oc1ccc(S(=O)(=O)c2ccc(-c3ccc(-c4ccc(S(=O)(=O)c5ccc([*])cc5)cc4)cc3)cc2)cc1 (39 atoms)\n",
      "0.12516358889561982\n",
      "-0.07388153688445062\n",
      "Saving [*]Oc1ccc(S(=O)(=O)c2ccc(-c3ccc(-c4ccc(S(=O)(=O)c5ccc([*])cc5)cc4)cc3)cc2)cc1 (39 atoms)\n",
      "0.14001820116475608\n",
      "-0.08873614846269336\n",
      "Saving [*]Oc1ccc(S(=O)(=O)c2ccc(-c3ccc(-c4ccc(S(=O)(=O)c5ccc([*])cc5)cc4)cc3)cc2)cc1 (39 atoms)\n",
      "0.12230354212361148\n",
      "-0.07102148825445416\n",
      "Saving [*]Oc1ccc(S(=O)(=O)c2ccc(-c3ccc(-c4ccc(S(=O)(=O)c5ccc([*])cc5)cc4)cc3)cc2)cc1 (39 atoms)\n",
      "0.14320447324140723\n",
      "-0.09192242315895513\n",
      "Saving [*]Oc1ccc(S(=O)(=O)c2ccc(-c3ccc(-c4ccc(S(=O)(=O)c5ccc([*])cc5)cc4)cc3)cc2)cc1 (39 atoms)\n",
      "0.1226865486162081\n",
      "-0.07140449755218202\n",
      "Saving [*]Oc1ccc(S(=O)(=O)c2ccc(-c3ccc(-c4ccc(S(=O)(=O)c5ccc([*])cc5)cc4)cc3)cc2)cc1 (39 atoms)\n",
      "0.12397262771201671\n",
      "-0.07269057499626318\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    visualize_atom_attention(\"/home/chenlidong/polyAttn/notebooks/\",smiles,atom_num,attns[idx][i][:atom_num,:atom_num],str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving [*]Oc1ccc(S(=O)(=O)c2ccc(-c3ccc(-c4ccc(S(=O)(=O)c5ccc([*])cc5)cc4)cc3)cc2)cc1 (39 atoms)\n",
      "0.20512821108671334\n",
      "0.20512820177323646\n"
     ]
    }
   ],
   "source": [
    "visualize_atom_attention(\"/home/chenlidong/polyAttn/notebooks/\",smiles,atom_num,torch.sum(attns,dim=1)[idx][:atom_num,:atom_num].T,\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [*]Oc1ccc(S(=O)(=O)c2ccc(-c3ccc(-c4ccc(S(=O)(=O)c5ccc([*])cc5)cc4)cc3)cc2)cc1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyG",
   "language": "python",
   "name": "py_38_torch_113_pyg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
